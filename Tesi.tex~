\documentclass[a4paper,openright,twoside,20pt]{report}
\usepackage[utf8x]{inputenc}
\usepackage[italian]{babel}
\usepackage{fancyhdr}
\usepackage{amssymb}
\usepackage{amsmath}    % need for subequations
\usepackage{graphicx}   % need for figures
\usepackage{verbatim}   % useful for program listings
\usepackage{color}      % use if color is used in text
\usepackage{subfigure}  % use for side-by-side figures
\usepackage{hyperref}   % use for hypertext links, including those to external documents and URLs
\author{Gian Pietro Farina}


\newtheorem{definizione}{Definizione}[chapter]
\newtheorem{proposizione}{Proposizione}[chapter]
\pagenumbering{arabic}
\begin{document}
\chapter{Introduzione}
%Nel capitolo intoduttivo si introdurranno il modello formale Vs quello computazionale,
%il concetto di sicurezza perfetta e quella computazionale per poi riprendere quest'ultima nel
%capitolo 1
\chapter{Il Modello Computazionale}
\section{L'avversario}
Il tipico avversario con cui si ha a che fare quando si studiano cifrari o protocolli crittografici nel modello computazionale,
è un avversario con risorse di calcolo \emph{limitate}. Limitate nel senso che si sceglie di porre un limite alla potenza di calcolo dell'avversario.
Questo significa che: non avremo a che fare con un avversario che ha una potenza computazionale infinita o un tempo illimitato a disposizione.
Sebbene siano stati ideati cifrari sicuri anche rispetto ad avversari non limitati\footnote{one-time pad ne \`e un esempio lampante.}, questi hanno alcuni difetti: come per esempio
il fatto che la chiave debba essere lunga quanto il messaggio o che sia utilizzabile una sola volta.
Per rappresentare in modo formale un avversario con risorse di calcolo limitate, lo si può pensare come un algoritmo appartenente ad una 
particolare classe di complessit\`a computazionale\footnote{un avversario \`e alla fine dei conti una macchina di Turing che esegue un algoritmo.}. \\
Da sempre si considerano efficienti gli algoritmi che terminano in un numero di passi polinomiale nella lunghezza dell'input, mentre si considerano inefficienti 
quelli che hanno una complessit\`a computazionale maggiore. Pu\`o sembrare quindi naturale immaginare gli avversari come degli algoritmi che terminano in un numero polinomiale di passi
rispetto alla lunghezza dell'input. Come si pu\`o notare non si fa nessuna assunzione particolare sul comportamento dell'avversario. Le uniche cose che sappiamo, sono che:
\begin{itemize}
 \item l'avversario non conosce la chiave, ma conosce l'algoritmo di cifratura utilizzato  e i parametri di sicurezza, come per esempio la lunghezza della chiave\footnote{Un famoso principio della crittografia afferma infatti che
l'algoritmo di cifratura non deve essere segreto e deve poter cadere nelle mani del nemico senza inconvenienti.}. 
 \item l'avversario vuole essere efficiente, ovvero polinomiale.
\end{itemize}

Non si fanno ipotesi sull'algoritmo che questo andr\`a ad eseguire.
Per esempio dato un messaggio cifrato $c=E_k(m)$, non ci aspettiamo che l'avversario non decida di utilizzare la stringa $c'$ tale che:  $c'=D_{k'}(E_k(m))$ con $k\neq k'$. 
Ovvero: sarebbe sbagliato supporre che l'avversario non cerchi di decifrare un messaggio mediante una chiave diversa 
da quella utilizzata per cifrarlo.
Nel modello computazionale i messaggi sono stringhe di bit e l'avversario pu\`o effettuare qualsiasi operazione su queste. Questa visione \`e, a differenza di quella 
che si ha nel modello formale, sicuramente molto pi\`u realistica\cite{DBLP:conf/crypto/2006}.\\

Non bisogna per\`o dimenticare che un avversario può sempre \emph{indovinare} il segreto che cerchiamo di nascondere, o che cifriamo. 
Per esempio: se il segreto che si cerca di nascondere ha una lunghezza di $n$ bit, l'avversario può sempre
lanciare una moneta $n$ volte e associare, via via, la testa della moneta al valore 1 e la croce al valore 0.
La probabilit\`a che l'avversario ottenga una stringa uguale al segreto \`e ovviamente di $\frac{1}{2^n}$. 
Questa probabilit\`a tende a 0 in modo esponenziale al crescere della lunghezza del segreto, ma per valori finiti di $n$ questa probabilit\`a non sar\`a mai 0.
\`E quindi pi\`u realistico cercare di rappresentare l'avversario come un algoritmo che, oltre a terminare in tempo polinomiale, ha
anche la possibilit\`a di effettuare scelte random.
La classe dei problemi risolti da questo tipo di algoritmi \`e indicata con la
sigla \emph{BPP} (i.e. \emph{Bounded-Probability Polynomial Time}).\\Un modo pi\`u formale di vedere questo tipo di algoritmi \`e il seguente: si suppone che la macchina di Turing che 
esegue l'algoritmo, oltre a ricevere l'input, diciamo x, riceve un input ausiliario r. Questa stringa di bit r, rappresenta una possibile sequenza di lanci di moneta.
Quando la macchina dovr\`a effettuare una scelta random, non dovr\`a far altro che prendere il successivo bit dalla stringa r, e prendere una decisione in base ad esso
(\`e, in effetti, come se avesse preso una decisione lanciando una moneta). Ecco quindi che il nostro tipico avversario si configura come un algoritmo polinomiale probabilistico.
\`E inoltre giustificato cercare di rendere sicuri\footnote{In qualsiasi modo si possa intendere il concetto di sicurezza. 
Vedremo che in seguito si daranno delle definizioni rigorose di questo concetto.} gli schemi crittografici rispetto, principalmente, a questo tipo di avversario.
Con questa scelta si cerca di rispettare il pi\`u possibile un famoso principio di Kerckhoffs\footnote{Auguste Kerckhoffs (19 Gennaio 1835 – 9 Agosto 1903) 
fu un linguista olandese e un famoso crittografo.} che afferma: 
\begin{quotation}
\em
Un cifrario deve essere, se non matematicamente, almeno praticamente indecifrabile.
\end{quotation}
\newpage
Non \`e quindi necessario dimostrare che un particolare schema crittografico sia inviolabile, ma basta dimostrare che:
\begin{itemize}
 \item in tempi ragionevoli lo si pu\`o violare solo con scarsissima probabilit\`a
 \item lo si pu\`o violare con alta probabilit\`a ma solo in tempi non ragionevoli
\end{itemize}
Sappiamo che il concetto di \emph{tempo ragionevole} \`e catturato dalla classe degli algoritmi polinomiali probabilistici. Vediamo ora di catturare il concetto di \emph{scarsa probabilit\`a}.
\section{Funzioni trascurabili e non $\dots$}
In crittografia i concetti di \emph{scarsa probabilit\`a} e di evento \emph{raro} vengono formalizzati attraverso la nozione di funzione trascurabile.
\begin{definizione}{Funzione Trascurabile (negligible).}
Sia $\mu: \mathbb{N} \rightarrow \mathbb{R^{+}}$ una funzione. Si dice che $\mu$ \`e trascurabile se e solo se per ogni polinomio $p$, esiste $C \in \mathbb{N} $ tale che $\forall n>C$: $\mu(n) < \frac{1}{p(n)}$.  
\end{definizione}
Una funzione trascurabile quindi, \`e una funzione che tende a 0 in modo pi\`u veloce dell'inverso di qualsiasi polinomio.
Un'altra definizione utile \`e la seguente:
\begin{definizione}{Funzione Distinguibile (noticeable).}
Sia $\mu: \mathbb{N} \rightarrow \mathbb{R^{+}}$ una funzione. Si dice che $\mu$ \`e distinguibile se e solo se esiste un polinomio $p$, tale per cui esiste $C \in \mathbb{N} $ tale che $\forall n>C$: $\mu(n) > \frac{1}{p(n)}$.  
\end{definizione}
Per esempio la funzione $n \rightarrow 2^{-\sqrt{n}}$ \`e una funzione trascurabile, mentre la funzione $n \rightarrow \frac{1}{n^2}$ non lo \`e. 
Ovviamente esistono anche funzioni che non sono n\'e trascurabili n\'e distinguibili. Per esempio, la seguente funzione definita per casi:
$f(n) = \begin{cases} 1, & \mbox{se } n\mbox{ \`e pari} \\ 0, & \mbox{se } n\mbox{ \`e dispari} \end{cases}$\\
non \`e n\'e trascurabile n\'e distinguibile. Questo perch\`e le definizioni precedenti, pur essendo molto legate, non sono l'una la negazione dell'altra.

Se sappiamo che in un esperimento un evento avviene con una probabilt\`a trascurabile,
quest'evento si verificher\`a con una probabilit\`a trascurabile anche se l'esperimento viene ripetuto molte volte (ma sempre un numero polinomiale di volte), e quindi per la legge dei grandi numeri, 
con una frequenza altrettanto trascurabile\footnote{In modo informale, la legge debole dei grandi numeri afferma che: per un numero grande di prove, 
la frequenza approssima la probabilit\`a di un evento.}. 
Le funzioni trascurabili infatti, godono di due particolari propriet\`a di chiusura, enunciate nella seguente:
\begin{proposizione}
Siano $\mu_1, \mu_2$ due funzioni trascurabili e sia $p$ un polinomio. Se $\mu_3 = \mu_1 + \mu_2$, e $\mu_4= p\cdot \mu_1$, allora $\mu_3, \mu_4$ sono funzioni trascurabili.  
\end{proposizione} 

Se quindi, in un esperimento, un evento avviene solo con probabilit\`a trascurabile, ci aspettiamo che, anche se ripetiamo l'esperimento un numero polinomiale di volte, questa probabilit\`a
rimanga comunque trascurabile.\\
Per esempio: supponiamo di avere un dado truccato in modo che la probabilit\`a di ottenere 1 sia trascurabile. Allora se lanciamo il dado un numero polinomiale di volte, la probabilit\`a
che esca 1 rimane comunque trascurabile.\\
\`E ora importantissimo notare che:
\textbf{gli eventi che avvengono con una probabilit\`a trascurabile possono essere ignorati per fini pratici}.
In \cite{1206501}, infatti leggiamo:
\begin{quotation}
\emph{Events that occur with negligible probability are so unlikely to occur that can be ignored for all practical purposes. Therefore,
a break of a cryptographic scheme that occurs with negligible probability is not significant.}
\end{quotation}
Potrebbe sembrare pericoloso utilizzare degli schemi crittografici che ammettono di essere violati con probabilit\`a trascurabile. 
Ma questa possiblit\`a \`e cosi remota, che se ci preoccupassimo, allora per amor di coerenza, dovremmo anche essere ragionevolmente sicuri di 
fare sei all'enalotto giocando una schedina semplice.
Finora abbiamo parlato sempre di funzioni che prendono in input un argomento non meglio specificato. 
Al crescere di questo parametro, le funzioni si comportano in modo diverso a seconda che siano trascurabili, oppure no.
Ma cosa rappresenta nella realt\`a questo input?
In genere questo valore rappresenta un generico parametro di sicurezza, indipendente dal segreto. Di solito lo si pensa come la lunghezza in bit delle chiavi.\\
Tutte le definizioni di sicurezza che vengono date nel modello computazionale e che utilizzano le probabilit\`a trascurabili, sono di tipo \emph{asintotico}.
Un template di definizione di sicurezza è il seguente \cite{1206501}:
\begin{quotation}
\emph{A scheme is secure if for every probablistic polynomial-time adversary \textbf{A} [...], the probability that \textbf{A} succeds in this attack [...]
is negligible}
\end{quotation}
Essendo questo schema di definizione asintotico (nel parametro di sicurezza, che indicheremo con \emph{n} d'ora in poi), \`e ovvio che non considera valori piccoli di \emph{n}.
Quindi: se si dimostra che un particolare schema crittografico \`e sicuro secondo una definizione di questo tipo, pu\`o benissimo capitare che per valori piccoli di \emph{n} lo schema
sia violabile con alta probablit\`a e in tempi ragionevoli.
\newpage

\section{Indistinguibilit\`a Computazionale}
Se due oggetti, sebbene profondamente diversi fra loro, non possono essere distinti, allora sono da un certo punto di vista equivalenti.
Nel caso della crittografia computazionale due oggetti sono computazionalmente equivalenti se nessuna algoritmo efficiente li pu\`o distinguere.
Possiamo immaginare che un algoritmo riesca a distinguere due oggetti, se quando gli si da in input il primo, lui da in output una costante \emph{c}, mentre se gli si 
fornisce come input il secondo da in output una costante \emph{$c'$} e ovviamente $c \neq c'$.
La definizione tipica di indistinguibilit\`a computazionale \`e data prendendo come oggetti da distinguere delle particolari distribuzioni statistiche detti \emph{ensembles}.

\begin{definizione}{Ensemble.}
Sia $I$ un insieme numerabile infinito.\\ $X=\{X_i\}_{i \in I}$ \`e un ensemble su $I$ se e solo se \`e una sequenza di variabili statistiche,
ognuna con una distribuzione di probabilit\`a uniforme.
\end{definizione}
Un ensemble \`e quindi una sequenza infinita di distribuzioni di probabilit\`a\footnote{siccome si parla di distribuzioni su stringhe di bit con lunghezza finita,
in crittografia computazionale si considerano ensemble che sono una sequenza inifinta di distribuzioni finite di stringhe di bit.}. Tipicamente le variabili dell'ensemble sono stringhe di lunghezza $i$.
$X_i$ \`e quindi la distribuzione di probabilit\`a uniforme su stringhe di lunghezza $i$.

Ora supponiamo di avere due ensemble $X$ e $Y$. Intuitivamente queste distribuzioni sono indistinguibili se nessun algoritmo (efficiente) pu\`o accettare infiniti elementi di $X_n$
(ovvero stampando $1$ su input preso da $X_n$) e scartare infiniti elementi di $Y_n$ (ovvero stampare $0$ su input preso da $Y_n$). \`E importante notare che sarebbe facile 
distinguere due \emph{singole} distribuzioni usando un approccio esaustivo, ecco perch\`e si considerano sequenze infinite di ditribuzioni finite.
In poche parole questi ensemble sono indistinguibile se ogni algoritmo accetta $x \in X_n$ se e solo se accetta $y \in Y_n$. Ovviamente il \emph{se e solo se} non pu\`o e non deve
essere inteso in senso \emph{classico} ma deve essere inteso in senso statistico.
Dopo questa breve introduzione all'indistinguibilit\`a siamo pronti per dare una definizione rigorosa:

\begin{definizione}{Indistinguibilit\`a computazionale.}
Due ensemble $X=\{X_n\}$, $Y=\{Y_n\}$ sono computazionalmente indistinguibili se e solo se per ogni algoritmo $D \in BPP$ (detto distinguitore) esiste $\mu$ trascurabile tale che:
 $\lvert Pr[D(1^n, X_n) = 1] - Pr[D(1^n, Y_n) = 1] \rvert \leq \mu(n)$.
\end{definizione}

Dove $Pr[D(1^n, X_n) = 1]$ \`e la probabilit\`a che, scegliendo $x$ secondo la distribuzione $X_n$ e fornendo questo valore al distinguitore insieme al valore $1^n$, il distinguitore stampi $1$.
Il fatto che al distinguitore si fornisca anche il valore del parametro di sicurezza in base unaria, serve ad esser sicuri che in ogni caso il distinguitore impieghi un tempo polinomiale nel parametro di sicurezza.
Infatti il distinguitore quando si trover\`a a dover leggere il primo parametro, necessariamente impiegher\`a un tempo polinomiale nel parametro di sicurezza, visto che questo \`e stato fornito in base unaria.

La definizione di indistinguibilit\`a computazionale cattura quindi il seguente concetto: se due ensemble sono computazionalmente indistinguibili, 
allora la probababilit\`a che un distinguitore riesca a discernere i valori provenienti da un insieme rispetto all'altro \`e trascurabile; di conseguenza agli occhi del distinguitore 
gli ensemble non sono differenti e quindi sono per lui equivalenti (o meglio computazionalmente equivalenti). 
Non \`e raro, nell'ambito scientifico in particolare, basarsi sul concetto generale di indistinguibilit\`a al fine di creare nuove classi di equivalenza di oggetti.

\begin{quotation}
\emph{The concept of efficient computation leads naturally to a new kind of equivalence netween objects: Objects are considered to be computatinally equivalent if they cannot be
differentiated by any efficient procedure.} We note that considering indistinguishable objects as equivalent is one of the basics paradigms of both science and real-life situations. Hence,
we believe that the notion of computational indistinguishability is a very natural one.\cite{519078}
\end{quotation}



\section{Pseudocasualit\`a e generatori pseudocasuali}
Argomento centrale di questa sezione \`e il concetto di \emph{pseudocasualit\`a} (pseudorandomness), applicato a stringhe di bit di lunghezza finita.
Parlare di pseudocasualit\`a applicata ad una \emph{singola} stringa ha poco senso quanto ne ha poco parlare di singola stringa casuale (random).
Infatti il concetto di casualit\`a (come quello di pseudocasualit\`a) si applica a distribuzioni di oggetti (stringhe di bit nel nostro caso).
In crittografia, la nozione di casualit\`a \`e fortemente legata a quella di distribuzione uniforme. Un insieme discreto di oggetti \`e caratterizzato
da una distribuzione uniforme se la probabilit\`a \`e equamente distribuita su tutti gli oggetti e quindi \emph{l'estrazione} di un elemento \`e del tutto casuale, 
perch\`e non ci sono elementi pi\`u probabili di altri.
In pratica esistono vari modi per ottenere bits random. Per esempio si possono utilizzare dei software basati sulle interazioni, considerate imprevedibili, 
che l'utente ha con la macchina: velocit\`a con cui preme i tasti della tastiera, movimenti del mouse ecc, ecc \dots 


Il concetto di pseudorandomness \`e un caso particolare di indistinuguibilit\`a, infatti una distribuzione \`e \emph{pseudorandom} se nessuna procedura efficiente, pu\`o distinguerla dalla distribuzione uniforme.
\begin{definizione}{Pseudoarandomness.}
Sia $U=\{U_{l(n)}\}_{n\in \mathbb{N}}$ la distribuzione uniforme sull'insieme di stringhe $\{0, 1\}^{l(n)}$.  L'ensemble $X=\{X_n\}_{n \in \mathbb{N}}$ \`e detto pseudorandom se e solo se
\`e computazionalmente indistinguibile dall'ensemble $U$\footnote{Con la notazione $A^k$ dove A \`e un insieme di simboli e $k$ un numero, si intende l'insieme di tutte le stringhe 
di lunghezza $k$ ottenibili con simboli di $A$.}.
\end{definizione}
Data questa definizione, possiamo finalmente definire formalmente cosa sia un generatore pseudorandom.
\begin{definizione}{Generatore Pseudorandom.}
Sia $l:$ $\mathbb{N}\rightarrow\mathbb{N}$ un polinomio. Sia G un algoritmo polinomiale deterministico tale che $\forall s \in \{0, 1\}^{n}$ $G(s) \in \{0, 1\}^{l(n)}.$
Allora $G$ \`e un generatore pseudorandom se e solo se valgono le seguenti condizioni:
\begin{itemize}
 \item Espansione: $\forall n: l(n) > n$
 \item Pseudocasualit\`a: $\forall D \in BPP, \exists \mu$ trascurabile tale che \\$\lvert Pr[D(1^{l(n)}, r) = 1] - Pr[D(1^{l(n)}, G(s)) = 1] \rvert \leq \mu(n)$\\con $r \in U_{l(n)}$ e $s \in U_{n}$
\end{itemize}
\end{definizione}

\newpage
\section{Dimostrazioni Basate su Games}






\chapter{CryptoVerif}
\chapter{Risultati Raggiunti}
\chapter{Conclusioni}
\lhead[\fancyplain{}{\bfseries\thepage}]{\fancyplain{}{\bfseries\rightmark}}
\bibliographystyle{alpha}	
\bibliography{myrefs}		
\end{document}          
