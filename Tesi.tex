\documentclass[a4paper,openright,twoside,12pt]{report}
\usepackage[utf8x]{inputenc}
\usepackage[italian]{babel}
\usepackage{fancyhdr}
\usepackage{amssymb}
\usepackage{amsmath}    % need for subequations
\usepackage{graphicx}   % need for figures
\usepackage{verbatim}   % useful for program listings
\usepackage{color}      % use if color is used in text
\usepackage{subfigure}  % use for side-by-side figures
\usepackage{hyperref}   % use for hypertext links, including those to external documents and URLs 
\usepackage{t1enc}
\usepackage{url}
\usepackage{algorithm}
\usepackage{algorithmic}
\author{Gian Pietro Farina}
\hyphenation{li-mi-ta-te li-mi-ta-ti e-qui-va-len-ti}

\newtheorem{definizione}{Definizione}[chapter]
\newtheorem{proposizione}{Proposizione}[chapter]
\pagenumbering{arabic}
\pagestyle{fancy}
% i comandi seguenti impediscono la scrittura in maiuscolo
% dei nomi dei capitoli e dei paragrafi nelle intestazioni
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}
\fancyhf{} % rimuove l’attuale contenuto dell’intestazione
            % e del pi\‘e di pagina
\fancyhead[LE,RO]{\bfseries\thepage}
\fancyhead[LO]{\bfseries\rightmark}
\fancyhead[RE]{\bfseries\leftmark}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0pt}
\addtolength{\headheight}{0.5pt} % riserva spazio per la linea
\fancypagestyle{plain}{%
   \fancyhead{} % ignora, nello stile plain, le intestazioni
   \renewcommand{\headrulewidth}{0pt} % e la linea
}


\newcommand{\foreach}[2]{\textbf{foreach #1} $\leq$ \textbf{#2} \textbf{do}}
\newcommand{\return}[1]{\textbf{return}(#1);}
\renewcommand{\do}{\textbf{do}}
\newcommand{\pipe}{ \textbf{|} \\ \\}
\newcommand{\setR}[2]{#1 $\xleftarrow{R}$ #2;}
\newcommand{\set}[2]{#1 $\leftarrow$ #2;}
\newcommand{\ifthen}[2]{\textbf{if} #1 \textbf{then} #2}
\newcommand{\find}[6]{\textbf{find #1} $\leq$ \textbf{#2 suchthat} (\textbf{defined}(#3) $\wedge$ #4)) \textbf{then} #5 \\ \textbf{else} #6}
\newcommand{\event}{\textbf{event}}
\newcommand{\myend}{\textbf{end}}
\begin{document}
\chapter{Introduzione}

$G_0=$ \foreach{iH}{qH} OH(x: bitstring):= \return{hash(x)}\pipe Ogen():=\setR{r}{seed}\set{pk}{pkgen(r)}\set{sk}{skgen(r)}\return{pk}\\
	(\foreach{iS}{qS} OS(m: bitstring):= \return{invf(sk, hash(m))})\pipe
	\find{u}{qS}{m[u]} {$m^{'}=m[u]$} {\myend} {\event} forge
	


Nel capitolo intoduttivo si introdurranno il modello formale Vs quello computazionale,
il concetto di sicurezza perfetta e quella computazionale per poi riprendere quest'ultima nel
capitolo 1
parlare di sicurezza TEORICA vs COPMUTAZINOALE
parlare delle assunzioni....e delle funzioni one-way.

Da quando la crittografia ha cessato di essere un'arte per assurgere allo stato di scienza\cite{diffiehelmann77}, sono nati almeno due modi profondamente diversi fra loro di
vedere la crittografia.\\In uno di questi, il modello \emph{formale}, le operazioni crittografiche sono rappresentate da espressioni simboliche, formali.
Nell'altro, il modello \emph{computazionale} le operazioni crittografiche sono viste come funzioni su stringhe di bit; le operazioni hanno una semantica probabilistica.
Il primo modello \`e stato teorizzato in \cite{}...
Il secondo modello trova le basi in lavori di altrettanto illustri studiosi \cite{}

In \cite{DBLP:journals/joc/AbadiR07} gli autori cercano per la primavolta di porre le basi per iniziare a collegare questi due modelli.

Parlare del teorema che unisce i due modelli
parlare del concetto di attaccante e di dimostrazioni che sfruttano 
il fatto che l'attaccante non può fare delle cose

parlare del concetto di funzione one-way.
\chapter{Il Modello Computazionale}
\section{L'Avversario}
Il tipico avversario con cui si ha a che fare quando si studiano cifrari o protocolli crittografici nel modello computazionale,
è un avversario con risorse di calcolo \emph{limitate}. Limitate nel senso che si sceglie di porre un limite alla potenza di calcolo dell'avversario.
Questo significa che non avremo a che fare con un avversario che ha una potenza computazionale infinita o un tempo illimitato a disposizione.\\
Sebbene siano stati ideati cifrari sicuri anche rispetto ad avversari non limitati\footnote{one-time pad ne \`e un esempio lampante.}, questi hanno alcuni difetti come per esempio
il fatto che la chiave debba essere lunga quanto il messaggio o che sia utilizzabile una sola volta.
Per rappresentare in modo formale un avversario con risorse di calcolo limitate, lo si può pensare come un algoritmo appartenente ad una 
particolare classe di complessit\`a computazionale\footnote{un avversario \`e, alla fine dei conti, una macchina di Turing che esegue un algoritmo.}. \\
Una linea di pensiero che accomuna ogni campo dell'informatica, considera efficienti gli algoritmi che terminano in un numero di passi polinomiale nella lunghezza dell'input, e inefficienti 
quelli che hanno una complessit\`a computazionale maggiore (e.g. esponenziale). 
La scelta di porre un limite alle risorse di calcolo dell'avversario \`e dettata dal buon senso.
\`E ragionevole infatti pensare che l'attaccante non sia infinitamente potente; \`e altrettanto ragionevole pensare che un attaccante non sia disposto ad impiegare un tempo \emph{eccessivo} per violare un schema crittografico.\\
Se un attaccante, infatti, per violare un cifrario, utilizzasse un algoritmo che impega l'et\`a dell'universo (stimata dai fisici intorno ai $13$ miliardi di anni), sicuramente non riuscirebbe a sfruttare questa \emph{vittoria}.
\`E logico, quindi, pensare che gli avversari vogliano essere \emph{efficienti}.
Pu\`o sembrare, quindi, naturale immaginare gli avversari come degli algoritmi che terminano in un numero polinomiale di passi
rispetto alla lunghezza dell'input.\\Come si pu\`o notare, non si fa alcuna assunzione particolare sul comportamento dell'avversario. Le uniche cose che sappiamo sono che:
\begin{itemize}
 \item l'avversario non conosce la chiave, ma conosce l'algoritmo di cifratura utilizzato  e i parametri di sicurezza, come per esempio la lunghezza della chiave\footnote{Un famoso principio della crittografia afferma che
l'algoritmo di cifratura non deve essere segreto e deve poter cadere nelle mani del nemico senza inconvenienti.}. 
 \item l'avversario vuole essere efficiente, ovvero polinomiale.
\end{itemize}

Non si fanno ipotesi sull'algoritmo che questo andr\`a ad eseguire.
Per esempio dato un messaggio cifrato $c=E_k(m)$, non ci aspettiamo che l'avversario non decida di utilizzare la stringa $c'$ tale che:  $c'=D_{k'}(E_k(m))$ con $k\neq k'$. 
Ovvero, sarebbe sbagliato supporre che l'avversario non cerchi di decifrare un messaggio mediante una chiave diversa 
da quella utilizzata per cifrarlo.
Nel modello computazionale i messaggi sono stringhe di bit e l'avversario pu\`o effettuare qualsiasi operazione su queste. Questa visione \`e, a differenza di quella 
che si ha nel modello formale, sicuramente molto pi\`u realistica\cite{DBLP:conf/crypto/2006}.\\

Non bisogna per\`o dimenticare che un avversario può sempre \emph{indovinare} il segreto che cerchiamo di nascondere, o che cifriamo. 
Per esempio: se il segreto che si cerca di nascondere ha una lunghezza di $n$ bit, l'avversario può sempre
lanciare una moneta $n$ volte e associare, via via, la testa della moneta al valore 1 e la croce al valore 0.
La probabilit\`a che l'avversario ottenga una stringa uguale al segreto \`e ovviamente di $\frac{1}{2^n}$. 
Questa probabilit\`a tende a 0 in modo esponenziale al crescere della lunghezza del segreto, ma per valori finiti di $n$ questa probabilit\`a non sar\`a mai 0.
\`E quindi pi\`u realistico cercare di rappresentare l'avversario come un algoritmo che, oltre a terminare in tempo polinomiale, ha
anche la possibilit\`a di effettuare scelte random.
La classe dei problemi risolti da questo tipo di algoritmi \`e indicata con la
sigla \emph{BPP} (i.e. \emph{Bounded-Probability Polynomial Time}).\\Un modo pi\`u formale di vedere questo tipo di algoritmi \`e il seguente: si suppone che la macchina di Turing che 
esegue l'algoritmo, oltre a ricevere l'input, diciamo $x$, riceva anche un input ausiliario $r$. Questa stringa di bit $r$, rappresenta una possibile sequenza di lanci di moneta.
Quando la macchina dovr\`a effettuare una scelta random, non dovr\`a far altro che prendere il successivo bit dalla stringa $r$, e prendere una decisione in base ad esso
(\`e, in effetti, come se avesse preso una decisione lanciando una moneta). Ecco quindi che il nostro tipico avversario si configura come un algoritmo polinomiale probabilistico.
\`E inoltre giustificato cercare di rendere sicuri\footnote{In qualsiasi modo si possa intendere il concetto di sicurezza. 
Vedremo che in seguito si daranno delle definizioni rigorose di questo concetto.} gli schemi crittografici rispetto, principalmente, a questo tipo di avversario.
Con questa scelta si cerca di rispettare il pi\`u possibile un famoso principio di Kerckhoffs\footnote{Auguste Kerckhoffs (19 Gennaio 1835 – 9 Agosto 1903) 
fu un linguista olandese e un famoso crittografo.} che afferma: 
\begin{quotation}
\em
Un cifrario deve essere, se non matematicamente, almeno praticamente indecifrabile.
\end{quotation}
Non \`e quindi necessario dimostrare che un particolare schema crittografico sia inviolabile, ma basta dimostrare che:
\begin{itemize}
 \item in tempi ragionevoli lo si pu\`o violare solo con scarsissima probabilit\`a.
 \item lo si pu\`o violare con alta probabilit\`a, ma solo in tempi non ragionevoli.
\end{itemize}
Sappiamo che il concetto di \emph{tempo ragionevole} \`e catturato dalla classe degli algoritmi polinomiali probabilistici. Vediamo ora di catturare il concetto di \emph{scarsa probabilit\`a}.
\section{Funzioni Trascurabili e non $\dots$}
In crittografia i concetti di \emph{scarsa probabilit\`a} e di evento \emph{raro} vengono formalizzati attraverso la nozione di funzione trascurabile.
\begin{definizione}{Funzione Trascurabile (negligible).}
Sia $\mu: \mathbb{N} \rightarrow \mathbb{R^{+}}$ una funzione. Si dice che $\mu$ \`e trascurabile se e solo se per ogni polinomio $p$, esiste $C \in \mathbb{N} $ tale che $\forall n>C$: $\mu(n) < \frac{1}{p(n)}$.  
\end{definizione}
Una funzione trascurabile, quindi, \`e una funzione che tende a 0 pi\`u velocemente dell'inverso di qualsiasi polinomio.
Un'altra definizione utile \`e la seguente:
\begin{definizione}{Funzione Distinguibile (noticeable).}
Sia $\mu: \mathbb{N} \rightarrow \mathbb{R^{+}}$ una funzione. Si dice che $\mu$ \`e distinguibile se e solo se esiste un polinomio $p$, tale per cui esiste $C \in \mathbb{N} $ tale che $\forall n>C$: $\mu(n) > \frac{1}{p(n)}$.  
\end{definizione}
Per esempio la funzione $n \rightarrow 2^{-\sqrt{n}}$ \`e una funzione trascurabile, mentre la funzione $n \rightarrow \frac{1}{n^2}$ non lo \`e. 
Ovviamente esistono anche funzioni che non sono n\'e trascurabili n\'e distinguibili. Per esempio, la seguente funzione definita per casi:
$f(n) = \begin{cases} 1, & \mbox{se } n\mbox{ \`e pari} \\ 0, & \mbox{se } n\mbox{ \`e dispari} \end{cases}$\\
non \`e n\'e trascurabile n\'e distinguibile. Questo perch\'e le definizioni precedenti, pur essendo molto legate, non sono l'una la negazione dell'altra.

Se sappiamo che, in un esperimento, un evento avviene con una probabilt\`a trascurabile,
quest'evento si verificher\`a con una probabilit\`a trascurabile anche se l'esperimento viene ripetuto molte volte (ma sempre un numero polinomiale di volte), e quindi per la legge dei grandi numeri, 
con una frequenza anch'essa trascurabile\footnote{In modo informale, la legge debole dei grandi numeri afferma che: per un numero grande di prove, 
la frequenza approssima la probabilit\`a di un evento.}. 
Le funzioni trascurabili, infatti, godono di due particolari propriet\`a di chiusura, enunciate nella seguente:
\begin{proposizione}
Siano $\mu_1, \mu_2$ due funzioni trascurabili e sia $p$ un polinomio. Se $\mu_3 = \mu_1 + \mu_2$, e $\mu_4= p\cdot \mu_1$, allora $\mu_3, \mu_4$ sono funzioni trascurabili.  
\end{proposizione} 

Se quindi, in un esperimento, un evento avviene solo con probabilit\`a trascurabile, ci aspettiamo che, anche se ripetiamo l'esperimento un numero polinomiale di volte, questa probabilit\`a
rimanga comunque trascurabile.\\
Per esempio: supponiamo di avere un dado truccato in modo che la probabilit\`a di ottenere 1 sia trascurabile. Allora se lanciamo il dado un numero polinomiale di volte, la probabilit\`a
che esca 1 rimane comunque trascurabile.\\
\`E ora importantissimo notare che:
\textbf{gli eventi che avvengono con una probabilit\`a trascurabile possono essere ignorati per fini pratici}.
In \cite{1206501}, infatti leggiamo:
\begin{quotation}
\emph{Events that occur with negligible probability are so unlikely to occur that can be ignored for all practical purposes. Therefore,
a break of a cryptographic scheme that occurs with negligible probability is not significant.}
\end{quotation}
Potrebbe sembrare pericoloso utilizzare degli schemi crittografici che ammettono di essere violati con probabilit\`a trascurabile, ma questa possibilit\`a \`e cosi remota, che se ci preoccupassimo, per amor di coerenza, dovremmo anche essere ragionevolmente sicuri di 
fare sei all'enalotto giocando una schedina semplice.
Finora abbiamo parlato sempre di funzioni che prendono in input un argomento non meglio specificato. 
Al crescere di questo parametro, le funzioni si comportano in modo diverso, a seconda che siano trascurabili, oppure no.
Ma cosa rappresenta nella realt\`a questo input?
Di solito, questo valore rappresenta un generico parametro di sicurezza, indipendente dal segreto. \`E comune immaginarlo come la lunghezza in bit delle chiavi.\\
D'ora in poi con affermazioni del tipo \flqq\l'algoritmo \`e polinomiale, o esponenziale\frqq, si intenderanno algoritmi polinomiali o esponenziali nella lunghezza (in bit) del parametro di sicurezza (indicato con $n$). Si utilizzer\`a questa assunzione anche quando si faranno affermazioni su funzioni trascurabili o meno. Quelle funzioni saranno trascurabili o meno nel parametro $n$.
Tutte le definizioni di sicurezza che vengono date nel modello computazionale e che utilizzano le probabilit\`a trascurabili, sono di tipo \emph{asintotico}.
Un template di definizione di sicurezza è il seguente \cite{1206501}:
\begin{quotation}
\emph{A scheme is secure if for every probablistic polynomial-time adversary \textbf{A} [...], the probability that \textbf{A} succeds in this attack [...]
is negligible}
\end{quotation}
Essendo questo schema di definizione asintotico (nel parametro di sicurezza \emph{n}), \`e ovvio che non considera valori piccoli di \emph{n}.
Quindi se si dimostra che un particolare schema crittografico \`e sicuro secondo una definizione di questo tipo, pu\`o benissimo capitare che per valori piccoli di \emph{n} lo schema
sia violabile con alta probabilit\`a e in tempi ragionevoli.
\section{Indistinguibilit\`a Computazionale}
Se due oggetti, sebbene profondamente diversi fra loro, non possono essere distinti, allora sono da un certo punto di vista equivalenti.
Nel caso della crittografia computazionale, due oggetti sono computazionalmente equivalenti se nessun algoritmo efficiente li pu\`o distinguere.
Possiamo immaginare che un algoritmo riesca a distinguere due oggetti, se quando gli si da in input il primo, lui da in output una costante \emph{c}, mentre se gli si 
fornisce come input il secondo da in output una costante \emph{$c'$} e ovviamente $c \neq c'$.
La definizione tipica di indistinguibilit\`a computazionale \`e data prendendo come oggetti da distinguere alcune particolari distribuzioni statistiche detti \emph{ensembles}.

\begin{definizione}{Ensemble.}
Sia $I$ un insieme numerabile infinito.\\ $X=\{X_i\}_{i \in I}$ \`e un ensemble su $I$ se e solo se \`e una sequenza di variabili statistiche.
\end{definizione}
Un \emph{ensemble} \`e quindi una sequenza infinita di distribuzioni di probabilit\`a\footnote{siccome si parla di distribuzioni su stringhe di bit con lunghezza finita,
in crittografia computazionale si considerano ensemble che sono una sequenza inifinta di distribuzioni finite di stringhe di bit.}. 
Tipicamente le variabili dell'ensemble sono stringhe di lunghezza $i$. $X_i$ \`e quindi una distribuzione di probabilit\`a su stringhe di lunghezza $i$.

Ora supponiamo di avere due ensemble $X$ e $Y$. Intuitivamente queste distribuzioni sono indistinguibili se nessun algoritmo (efficiente) pu\`o accettare infiniti elementi di $X_n$
(per esempio stampando $1$ su input preso da $X_n$) e scartare infiniti elementi di $Y_n$ (per esempio stampare $0$ su input preso da $Y_n$). \`E importante notare che sarebbe facile 
distinguere due \emph{singole} distribuzioni usando un approccio esaustivo, ecco perch\'e si considerano sequenze infinite di ditribuzioni finite.
In poche parole questi ensemble sono indistinguibili se ogni algoritmo (efficiente) accetta $x \in X_n$ se e solo se accetta $y \in Y_n$. Ovviamente il \emph{se e solo se} non pu\`o e non deve
essere inteso in senso \emph{classico}, ma deve essere inteso in senso statistico. Poich\'e in crittografia si \`e soliti indicare con $U_m$ una variabile
uniformemente distribuita sull'insieme delle stringhe di lunghezza $m$, chiameremo $U=\{U_n\}_{n \in \mathbb{N}}$ l'ensemble uniforme.
Dopo questa breve introduzione all'indistinguibilit\`a siamo pronti per dare una definizione rigorosa:

\begin{definizione}{Indistinguibilit\`a computazionale.}
Due ensemble $X=\{X_n\}$, $Y=\{Y_n\}$ sono computazionalmente indistinguibili se e solo se per ogni algoritmo $D \in BPP$ (detto distinguitore) esiste $\mu$ trascurabile tale che:
\begin{center}$\lvert Pr[D(1^n, X_n) = 1] - Pr[D(1^n, Y_n) = 1] \rvert \leq \mu(n)$.\end{center}
\end{definizione}
Nella definizione precedente: $Pr[D(1^n, X_n) = 1]$ \`e la probabilit\`a che, scegliendo $x$ secondo la distribuzione $X_n$ e fornendo questo valore al distinguitore insieme al valore $1^n$, il distinguitore stampi $1$.
Il fatto che al distinguitore si fornisca anche il valore del parametro di sicurezza in base unaria, serve ad esser sicuri che in ogni caso il distinguitore impieghi un tempo polinomiale 
nel parametro di sicurezza.
Infatti, il distinguitore quando si trover\`a a dover leggere il primo parametro, necessariamente impiegher\`a un tempo polinomiale nel parametro di sicurezza, visto che questo \`e stato 
fornito in base unaria\footnote{ignoreremo, d'ora in poi, questo cavillo formale.}.

La definizione di indistinguibilit\`a computazionale cattura quindi il seguente concetto: se due ensemble sono computazionalmente indistinguibili, 
allora la probababilit\`a che un distinguitore riesca a discernere i valori provenienti da un insieme rispetto all'altro \`e trascurabile; di conseguenza agli occhi del distinguitore 
gli ensemble non sono differenti e quindi sono per lui equivalenti (o meglio computazionalmente equivalenti o ancora, indistinguibili in tempo polinomiale). 
Non \`e raro, nell'ambito scientifico in particolare, basarsi sul concetto generale di indistinguibilit\`a al fine di creare nuove classi di equivalenza di oggetti.
\newpage
\begin{quotation}
\emph{The concept of efficient computation leads naturally to a new kind of equivalence between objects: Objects are considered to be computationally equivalent if they cannot be
differentiated by any efficient procedure.} We note that considering indistinguishable objects as equivalent is one of the basics paradigms of both science and real-life situations. Hence,
we believe that the notion of computational indistinguishability is a very natural one.\cite{519078}
\end{quotation}



\section{Pseudocasualit\`a e Generatori Pseudocasuali}
Argomento centrale di questa sezione \`e il concetto di \emph{pseudocasualit\`a} (pseudorandomness), applicato a stringhe di bit di lunghezza finita.
Parlare di pseudocasualit\`a applicata ad una \emph{singola} stringa, ha poco senso quanto ne ha poco parlare di singola stringa casuale (random).
Il concetto di casualit\`a (come quello di pseudocasualit\`a) si applica, infatti, a distribuzioni di oggetti (stringhe di bit nel nostro caso) e non a singoli oggetti.\\
La nozione di casualit\`a \`e fortemente legata a quella di distribuzione uniforme. Un insieme di oggetti \`e caratterizzato
da una distribuzione uniforme se la probabilit\`a \`e equamente distribuita su tutti gli oggetti. Quindi \emph{l'estrazione} di un elemento \`e del tutto casuale, 
perch\'e non ci sono elementi pi\`u probabili di altri.

Il concetto di pseudorandomness \`e un caso particolare di indistinuguibilit\`a, infatti una distribuzione \`e \emph{pseudorandom} se nessuna procedura efficiente, 
pu\`o distinguerla dalla distribuzione uniforme.
\begin{definizione}{Pseudorandomness.}
L'ensemble $X=\{X_n\}_{n \in \mathbb{N}}$ \`e detto pseudorandom se e solo se $ \exists l:$ $\mathbb{N}\rightarrow\mathbb{N}$ tale che: 
$X$ \`e computazionalmente indistinguibile da $U=\{U_{l(n)}\}_{n \in \mathbb{N}} $.  
\end{definizione}
Data questa definizione, possiamo finalmente definire formalmente cosa sia un generatore pseudorandom.\newpage
\begin{definizione}{Generatore Pseudorandom.}
Sia $l:$ $\mathbb{N}\rightarrow\mathbb{N}$ un polinomio detto fattore d'espansione. 
Sia G un algoritmo polinomiale deterministico tale che: $\forall s \in \{0, 1\}^{n}$ $G(s) \in \{0, 1\}^{l(n)}.$
Allora $G$ \`e un generatore pseudorandom se e solo se valgono le seguenti condizioni:
\begin{itemize}
 \item Espansione: $\forall n: l(n) > n$
 \item Pseudocasualit\`a: $\forall D \in BPP, \exists \mu$ trascurabile tale che \begin{center}
                                                   $\lvert Pr[D(r) = 1] - Pr[D(G(s)) = 1]$                               
                                                                                 \end{center} con $r \in U_{l(n)}$ e $s \in U_{n}$
\end{itemize}
\end{definizione}

Quindi: se data una stringa di bit $s \in U_{n}$, nessun distinguitore efficiente riesce a distinguere (con una probabilit\`a non trascurabile) $G(s)$ da una stringa $r \in U_{l(n)}$, allora 
$G$ \`e un generatore pseudorandom. Il suo output, infatti, non \`e distinguibile dalla distribuzione effettivamente uniforme.

\`E importante per\`o notare, che la stringa in output di un generatore pseudorandom \`e fortemente differente da una stringa effettivamente random. Per rendere pi\`u chiara questa distinzione procederemo
con un importante esempio.
Supponiamo di avere un generatore pseudorandom \emph{G} con fattore d'espansione $l(n)=2n$.
L'insieme $A=\{0, 1\}^{2n}$ ha, ovviamente, una cardinalit\`a pari a $2^{2n}$. Fissando quindi una certa stringa $x \in A$, 
questa ha una probabilit\`a di esser scelta in maniera random pari a: $\frac{1}{\lvert A \rvert} = \frac{1}{2^{2n}}$.

Ragioniamo adesso sull'output del generatore $G$. Questo prende un input appartenente al dominio: $B=\{0, 1\}^{n}$. 
Anche considerando il caso \emph{migliore} di un generatore iniettivo\footnote{una generica funzione $f$ \`e iniettiva se e solo se $\forall x_1, x_2:$ $x_1 \neq x_2 \Rightarrow f(x_1) \neq f(x_2)$.},
il codominio di $G$ avr\`a una cardinalit\`a pari a quella del dominio ovvero $2^{n}$. La maggior parte degli elementi dell'insieme $A$ non ricadr\`a 
nell'output di $G$; questo a causa dell'abissale differenza di cardinalit\`a fra gli insiemi $G(B)$ e $A$.
Quindi la probabilit\`a che una stringa scelta in maniera uniforme dall'insieme $A$ ricada nel codominio di $G$ \`e di $\frac{2^{n}}{2^{2n}}$, cio\`e $2^{-n}$.
In teoria, quindi, \`e facile immaginare un distinguitore $D$ che riesca a discernere l'output di $G$ dalla distribuzione uniforme con probabilit\`a non trascurabile.
Supponiamo che $D$ prenda in input $y \in A$. Tutto ci\`o che $D$ deve fare \`e ricercare in modo esaustivo un $w \in B$ tale che $G(w) = y$.
Se $y \in G(B)$ allora $D$ se ne accorger\`a con probabilit\`a 1, mentre se $y$ \`e stato scelto in maniera uniforme dall'insieme $A$, $D$ stamper\`a 1 con probabilit\`a $2^{-n}$. 
\newpage Quindi abbiamo che:
\begin{center}
$\lvert Pr[D(r)=1] - Pr[D(G(s))=1]\rvert \geq 1 - 2^{-n}$ con $r \xleftarrow{R} A$ e $s \xleftarrow{R} B$\footnote{con la notazione $s \xleftarrow{R} O$, si intende la scelta dell'elemento 
$s \in O$ in maniera random.}.
\end{center} 
Il membro a destra della disequazione \`e una funzione distinguibile. Sembrerebbe quindi che $G$ non sia un generatore pseudorandom.
C'\`e un' importante constatazione da fare per\`o. Il distinguitore $D$ non \`e efficiente! Infatti impiega un tempo esponenziale nel parametro $n$, e non polinomiale.
La distribuzione generata da $G$ dunque, \`e si ben lontana dall'essere uniforme, ma questo non \`e importante dal momento che nessun distinguitore che viaggia in tempo polinomiale pu\`o 
accorgersene.


Nella pratica lo scopo di $G$ \`e prendere in input un $seed$ random, e da quello generare una variabile pseudocasuale molto pi\`u lunga. Si inutisce da questo la grandissima
importanza che hanno i generatori pseudorandom in crittografia. Per esempio il seed potrebbe corrispondere alla chiave di un cifrario, mentre l'output di $G$ di lunghezza $k$ potrebbe
essere il valore con cui viene fatto lo $XOR$ del messaggio (anch'esso di lunghezza $k$); otteniamo cos\`i una versione del one-time pad basato su una chiave pi\`u corta del messaggio.
Siccome una stringa pseudorandom appare, ad un distinguitore efficiente $D$, come una stringa random, $D$ non ottiene un vantaggio sensibile nel passaggio dal vero one-time pad
al one-time pad che usa una chiave pseudorandom. In generale i generatori pseudorandom sono molto utili in crittografia per creare schemi crittografici simmetrici.

\section{Dimostrazioni Basate su Games}
In questo paragrafo si cercher\`a di spiegare cosa sono nell'ambito della crittografia i \emph{games}\footnote{che intenderemo letteralmente come "giochi"} e come sono strutturate la
maggior parte delle dimostrazioni che utilizzano sequenze di games.\\Si possono trovare approfondimenti riguardo a questi concetti nel lavoro di Shoup \cite{shoup}.
Quella basata sul concetto di game\footnote{game hopping tecnique} \`e una tecnica molto utilizzata per provare la sicurezza di primitive crittografiche o di protocolli crittografici.
Questi games sono giocati da un' ipotetica entit\`a maligna, l'attaccante, e da un'ipotetica parte benigna di solito chiamato sfidante\footnote{perch\`e \emph{sfida} l'attaccante a 
vincere questo gioco.}. 
\`E difficile dare una definizione formale di game, infatti il concetto di game cambia, sebbene in maniera non sensibile, da situazione a situazione da ambiente ad ambiente e 
da dimostrazione a dimostrazione (sia che queste siano fatte a mano sia che queste siano automatiche e quindi dipendenti dal framework in cui vengono costruite).
Intuitivamente per\`o, i game possono essere immaginati come un insieme di azioni, modellate in una particolare algebra di processi, 
che servono a specificare il comportamento dei partecipanti al gioco, ovvero le entit\`a che partecipano come \emph{principals} al protocollo crittografico.\\
Il lettore trover\`a utile pensarli, almeno nell'ambito di questa tesi, come insiemi di processi che, fra le altre cose, forniscono un'interfaccia all'attaccante attraverso degli 
\emph{oracoli} che possono resitituire dei valori all'attaccante. Questi oracoli, prima di ritornare il valore, possono effettuare calcoli, dichiarare ed utilizzare variabili che non saranno
visibili all'esterno.\\Si deve pensare agli oracoli come delle scatole nere inaccessibili dall'esterno. Questi oracoli una volta interrogati forniscono una risposta,
e questo \`e il massimo livello di interazione che dall'esterno si pu\`o avere con queste entit\`a.\\ \\
Il principio che seguono le dimostrazioni di sicurezza basate su sequenze di game \`e quello di partire da un game iniziale $G_0$ che modella il protocollo crittografico reale.
In $G_0$ esiste la probabilit\`a non nulla che un evento \emph{negativo} possa accadere (immaginiamolo come una sorta di vittoria da parte dell'attaccante).
Ora, in generale, si procede effettuando delle modifiche al game $G_i$ ottenendo un game $G_{i+1}$ 
tale che $G_i$ e $G_{i+1}$ sono computazionalmente indistinguibili. Le modifiche che si effettuano fra un game e un altro devono introdurre delle differenze computazionalmente irrilevanti.
Queste modifiche possono essere viste come regole di riscrittura delle distribuzioni di probabilit\`a delle variabili in gioco nei game.
Se per esempio in un game $G_i$ un processo ha a che fare con un variabile random, e noi nel game $G_{i+1}$ la sostituiamo con una variabile che invece \`e pseudorandom, non introduciamo
modifiche computazionalmente rilevanti, e quindi il passaggio \`e lecito visto che i due game non sono distinguibili se non con probabilit\`a trascurabile.
Alla fine si deve arrivare ad un game $G_f$ in cui \emph{l'evento} non pu\`o accadere. Se, quindi, nel game finale l'attaccante non ha possibilit\`a di vincere, e il game finale
\`e computazionalmente indistinguibile dal penultimo, e il penultimo lo \`e dal terzultimo e il terzultimo lo \`e dal quartultimo e cosi via fino al primo, allora
il game finale \`e computazionalmente indistinguibile dal primo\footnote{Ricordiamo infatti che la somma di due probabilit\`a trascurabili rimane trascurabile.}. 
Adesso, quindi, se nel game iniziale esiste la possibilit\`a che un evento avvenga, e nel game finale no,
possiamo dare un limite superiore alla probabilit\`a che l'evento avvenga nel game iniziale. Questo limite \`e la somma di tutte le probabilit\`a\footnote{ovviamente tutte trascurabili, 
visto che i due game sono computazionalmente indistinguibili.} con cui un attaccante riesce a distinguere un game dal successivo.

\`E importante dire che, anche nel modello formale si possono utilizzare le sequenze di game, la differenza \`e che due game successivi non sono computazionalmente indistinguibili 
ma sono perfettamente indistinguibili. In particolare quello che si vuole sottolineare \`e che, se in una sequenza di game, $G_b$ e $G_a$ sono l'uno il successore dell'altro, 
allora i due game 
devono appartenere ad una stessa classe di equivalenza indotta dalla particolare relazione di equivalenza che il modello in cui si sta costruendo la sequenza sfrutta.
Nel modello formale questa relazione sar\`a l'equivalenza osservazionale mentre in quello computazionale sar\`a l'indistinguibilit\`a computazionale.
\chapter{CryptoVerif}
\section{Introduzione al Tool}
CryptoVerif \`e un \emph{dimostratore} automatico che lavora direttamente nel modello computazionale. \`E un tool molto recente e in continuo sviluppo.\\
CryptoVerif \`e stato scritto da Bruno Blanchet\footnote{Ricercatore al LIENS (Computer Science Laboratory of Ecole Normale Supérieure)} in ML. 
Si possono trovare pi\`u informazioni nella home page di Blanchet\footnote{\url{http://www.di.ens.fr/~blanchet/index-eng.html}}.
Questo tool \`e utilizzato per dimostrare propriet\`a di segretezza e autenticazione Queste prove si basano sulla tecnica delle sequenze di game.
Il tool \`e liberamente scaricabile\footnote{\url{http://www.cryptoverif.ens.fr/cryptoverif.html}} sotto la licenza CeCill\footnote{http://www.cecill.info/licences/}.
CryptVerif \`e stato gi\`a utilizzato per dimostrare la correttezza di alcuni protocolli crittografici, come per esempio: FDH \cite{BlanchetPointchevalCrypto06}, 
Kerberos \cite{BlanchetJaggardScedrovTsayAsiaCCS08}.
\section{Un Esempio: FDH}
Full Domain Hash \`e uno schema di firma che segue il paradigma \emph{hash-and-sign}\footnote{Questo paradigma vuole che, dato un messaggio $m$ se ne ritorni 
la firma di $hash(m)$ e non la firma di $m$, dove la funzione hash \`e pu\`o essere istanziata con qualsiasi funzione hash collision resistant. 
Si ottiene cos\`i una firma di lunghezza fissa e non dipendente dalla lunghezza del messaggio}. 
Quella che a breve seguir\`a \`e una sequenza di game costruita dal CryptoVerif che d\`a un limite alla probabilit\`a che un attaccante riesca a forgiare una firma valida
per un messaggio.
L'input che si fornisce al CryptoVerif consta di un game iniziale chiamato $G_0$ in cui si modella la sicurezza dello schema e delle equivalenze necessarie a
CryptoVerif per effettuare le modifiche ai game.
La descrizione dello schema di firma \emph{FDH} attraverso il seguente game:
\begin{center}
$G0= \textbf{foreach}$ $iH \leq qH$ $\textbf{do}$ $OH(x : bitstring) := \textbf{return}(hash(x ))$ |\\
	  $Ogen() := r \xleftarrow{R} seed ; pk \leftarrow pkgen(r ); sk \leftarrow skgen(r ); \textbf{return}(pk )|$\\
    $(\textbf{foreach}$ $iS \leq qS$ $\textbf{do}$ $OS(m : bitstring) := \textbf{return}(invf(sk , hash(m)))$|\\
  $ OT (m : bitstring, s : D) := \textbf{if} f(pk , s) = hash(m ) \textbf{then}$
   $ \textbf{find}$ $u$ $\leq$ $qS$ $\textbf{suchthat}$ $(\textbf{defined}(m[u]) ∧ m = m[u])$ $\textbf{then end}$\\
                                                            $\textbf{else event}$ $forge$
\end{center}
Possiamo vedere come in questo game si forniscano $qH$ copie dell' oracolo $OH$ che ritorna l'hash della stringa che gli si fornisce in input: $x$.
Abbiamo poi il processo $Ogen()$ che ritorna al contesto una chiave pubblica dopo aver creato, partendo da un seme random, una coppia (chiave privata, chiave pubblica).
Abbiamo poi $qS$ oracoli $OS$ che si occupano di fornire una firma del messaggio che gli viene dato in input. Infine abbiamo un singolo oracolo $OT$ che si occupa di verificare
se la firma $s$ \`e valida per il messaggio $m^{'}$. In particolare se $hash(m^{'}) \neq f(pk, s)$ allora la firma non \`e valida per il messaggio. Se invece $hash(m^{'}) = f(pk, s)$
l'oracolo si occupa di verificare se, per il messaggio $m^{'}$, \`e stata mai rilasciata una firma dall'oracolo $OS$, in caso affermativo il processo termina, altrimenti significa che 
il contesto, ovvero l'attaccante, \`e stato in grado di forgiare una firma valida per il messaggio, e quindi \`e avvenuto l'evento \emph{forge}.
Questo game modella la sicurezza dello schema di firma FDH. Notiamo come l'attaccante non sia modellato esplicitamente, infatti non possiamo fare nessuna assunzione su questo.
Possiamo immaginare un attaccante come un altro processo messo in parallelo con questo game. In gergo l'attaccante viene anche detto anche \emph{contesto}.
Per poter trasformare un game in un altro CryptoVerif ha bisogno di alcune equivalenze da poter utilizzare.
Le definizioni in CryptoVerif vengono fornite attraverso delle equivalenze che possono essere viste come regole di riscrittura delle distribuzioni di probabilit\`a delle variabili in
gioco.
Queste regole di riscrittura di un generico elemento L in un generico elemento R possono valere incondizionatamente, oppure possono valere a meno di una certa probabilit\`a.
Nel secondo caso la riscrittura di un termine L nell'equivalente R comporta l'introduzione di una differenza non nulla.
Per esempio la definizione di \emph{one-wayness} viene fornita a CryptoVerif mediante questa equivalenza:
\newpage
\begin{center}
\begin{verbatim}
                            R
     foreach ik ≤ nk do r ← seed ; (Opk() := return(pkgen(r))
                                  R
          | foreach if ≤ nf do x ← D; (Oy() := return(f(pkgen(r), x))
               | foreach i1 ≤ n1 do Oeq(x : D) := return(x = x)
               | Ox() := return(x)))
                                                                        
                            R
≈
pow foreach ik ≤ nk do r ← seed ; (Opk() := return(pkgen (r))
                                  R
          | foreach if ≤ nf do x ← D; (Oy() := return(f (pkgen (r), x))
               | foreach i1 ≤ n1 do Oeq(x : D) :=
                    if defined(k) then return(x = x) else return(false)
               | Ox() := k ← mark; return(x)))
\end{verbatim}
\end{center}

Questa equivalenza cattura e definisce il concetto di funzione one-way. Supponiamo infatti che la funzione f non sia one-way, esister\`a dunque un avversario efficiente A che riuscir\`a ad invertire 
la funzione. Questo avversario sar\`a dunque in grado di distinguere i due membri dell'equivalenza L<=>R. Infatti L'avversario non dovr\`a far altro che chiamare Oy(), e invertire la funzione.
Quando poi chiamer\`a Oeq fornendo la preimmagine di y da lui calcolata se Oeq appartiene al primo membro allora Oeq tironer\`a sempre true, mentre se appartiene al secondo ritorner\`a sempre false.

Supponiamo invece che $f$ si effettivamente one-way. Allora non esister\`a nessun attaccante efficiente che riesca ad invertire $f$. L'unico modo che ha quindi un attaccante
per invertire la funzione \`e chiamare oltre Ox() e ottenere cos\`i una preimmagine valida. Se però l'attaccante chiama Ox() allora L e R sono indistinguibili (a meno di probabilit\`a trascurabili).
Infatti se l'Ox() chiamato dall'attaccante apaprtiene ad L allora viene semplicemente ritornrata x. Se invece Ox() appartiene ad R l'oracolo prima di ritornare x segna k con una costante mark.
Quando poi L'attaccante chiama Oeq() nel caso Oeq sia in R allora Oeq effettua un test e se k \`e stato definito ritorna quello che avrebbe ritornato L.Oeq. SE invece k non \`e stato definito
allora siginifica che l'attaccante non ha richiamato Oeq e quindi \`e probabilissimo che non sia riuscto ad invertire la f e quindi Oeq ritorna false.

Un'ulteriore definizione viene fornita al CryptoVerif, quella di funzione hash. La funzione hash viene fornita attraverso il seguente codice:
\begin{center}
 \begin{verbatim}
 726 equiv foreach iH <= nH do OH(x:hashinput) := return(hash(x)) [all]
 727       <=(0)=>
 728       foreach iH <= nH do OH(x:hashinput) :=
 729     find[unique] u <= nH suchthat defined(x[u],r[u]) 
	      && otheruses(r[u]) && x= x[u] then return(r[u]) 
	      else r <-R hashoutput; return(r).
 730 
 731 let hashoracle =
 732         foreach iH <= qH do
 733     OH(x:hashinput) :=
 734     return(hash(x)).
 \end{verbatim}
\end{center}

La funzione hash \`e intesa implementata nel modello dell'oracolo random. Ovvero la funzione se non \`e mai stata richiamata su un particolare valore $x_0$ allora ritorna un
valore random, altrimenti ritorna il valore che ha ritornato precedentemente. Questo viene fatto salvando il valore ritornato per un particolare input in un array, epoi
al momento della chiamata effettuando un look up nell'array.


 925 forall r:seed, x:D, x':D;
 926     (x' = invf(skgen(r),x)) = (f(pkgen(r),x') = x).



forall k:skey, x:D, x':D; (invf(k,x) = invf(k,x')) = (x = x').

 915 forall k:pkey, x:D, x':D; (f(k,x) = f(k,x')) = (x = x').
 916 forall k:pkey, x:D, x':D; (f'(k,x) = f'(k,x')) = (x = x').


 911 forall r:seed, x:D; f(pkgen(r), invf(skgen(r), x)) = x.

forall r:seed, x:D; invf(skgen(r), f(pkgen(r), x)) = x.



\chapter{Risultati Raggiunti}
\chapter{Conclusioni}
\lhead[\fancyplain{}{\bfseries\thepage}]{\fancyplain{}{\bfseries\rightmark}}
\bibliographystyle{alpha}	
\bibliography{myrefs}		
\end{document}          
